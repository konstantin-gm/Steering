# -*- coding: utf-8 -*-
"""nnpid_red.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DG6Fl2FyVfKZpip-a7jSEKK7KP6FdW3-
"""

import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# ---------- Plant model with Wiener process noise ----------

# SDE: dx = (-a*x + b*u)*dt + sigma_p*dW_t
class FirstOrderPlant:
    def __init__(self, a=1.0, b=1.0, dt=0.02, noise_std=0.1):
        """
        a, b      : plant parameters
        dt        : time step
        noise_std : sigma_p in dx = ... + sigma_p dW
        """
        self.a = a
        self.b = b
        self.dt = dt
        self.noise_std = noise_std

    def step(self, x, u, noise_mult = 1):
        """
        One Euler–Maruyama integration step.

        x, u: tensors
        returns: next true state x_{k+1}
        """
        drift = -self.a * x + self.b * u

        if self.noise_std > 0.0:
            # Wiener increment ~ N(0, dt)
            w_increment = torch.randn_like(x) * (self.dt ** 0.5)
            noise = self.noise_std * w_increment * noise_mult
        else:
            noise = 0.0

        x_next = x + self.dt * drift + noise
        return x_next


# ---------- Neural "PID-like" controller with noise input ----------

class NeuralPID(nn.Module):
    def __init__(self, hidden_size=32):
        super().__init__()
        # inputs: e, I, D, noise_hat -> 4 features
        self.net = nn.Sequential(
            nn.Linear(4, hidden_size),
            nn.Tanh(),
            #nn.Linear(hidden_size, hidden_size),
            #nn.Tanh(),
            nn.Linear(hidden_size, 1),
        )

    def forward(self, e, i, d, noise_hat):
        """
        e, i, d, noise_hat: tensors of same shape
        returns: control u
        """
        inp = torch.stack([e, i, d, noise_hat], dim=-1)  # [..., 4]
        u = self.net(inp).squeeze(-1)
        return u

# ---------- Simulation loop (process + measurement noise + estimator) ----------

def simulate_episode(
    controller,
    plant,
    setpoint,
    T=200,
    dt=0.02,
    device="cpu",
    train_mode=True,
    meas_noise_std=0.05,
    alpha_noise_est=0.05,
):
    """
    Simulate one trajectory for a fixed setpoint.

    controller     : NeuralPID module
    plant          : FirstOrderPlant instance (process noise inside)
    setpoint       : float
    meas_noise_std : sigma_m in y = x + sigma_m * N(0,1)
    alpha_noise_est: smoothing factor for noise variance estimator

    returns:
        xs: [T, 1] true states over time
        us: [T, 1] control signals over time
    """
    if train_mode:
        controller.train()
    else:
        controller.eval()

    # True state
    x = torch.zeros(1, device=device)         # x0 = 0

    # First measurement (at t=0)
    if meas_noise_std > 0.0:
        meas_noise = meas_noise_std * torch.randn_like(x)
    else:
        meas_noise = 0.0
    y = x + meas_noise

    # PID-like internal states (based on noisy signals)
    i_term = torch.zeros(1, device=device)
    prev_e = torch.zeros(1, device=device)

    # Noise variance estimator
    noise_var_hat = torch.full_like(x, 1e-6)  # shape [1], same as x, e, i, d
    noise_hat = noise_var_hat.sqrt()

    setpoint_tensor = torch.tensor([setpoint], device=device)

    xs = []
    us = []

    # For prediction using deterministic model: we need a,b
    a = plant.a
    b = plant.b

    for t in range(T):
        # Error based on noisy measurement
        e = setpoint_tensor - y
        i_term = i_term + e * dt
        d_term = (e - prev_e) / dt
        prev_e = e

        # Controller sees (e, I, D, noise_hat)
        u = controller(e, i_term, d_term, noise_hat)

        # Plant step: true state evolves with process noise
        mult = 1
        # if t > T/2:
        #   x_next = plant.step(x, u, 1)
        #   mult = 10
        # else:
        #   x_next = plant.step(x, u)
        x_next = plant.step(x, u)

        # New measurement
        if meas_noise_std > 0.0:
            meas_noise = meas_noise_std * torch.randn_like(x_next)
        else:
            meas_noise = 0.0
        y_next = x_next + meas_noise * mult

        # --- Noise level estimation (based on prediction error) ---
        # Predict next measurement using deterministic model (no noise)
        y_pred = y + dt * (-a * y + b * u)
        residual = y_next - y_pred   # includes process + measurement noise
        noise_var_hat = (
            (1.0 - alpha_noise_est) * noise_var_hat
            + alpha_noise_est * (residual ** 2)
        )
        noise_hat = (noise_var_hat + 1e-8).sqrt()

        # Move to next step
        x = x_next
        y = y_next

        xs.append(x)
        us.append(u)

    xs = torch.stack(xs)  # [T, 1] true states
    us = torch.stack(us)  # [T, 1] controls
    return xs, us

# ---------- Training loop ----------

def train_controller(
    controller,
    plant,
    device="cpu",
    num_epochs=300,
    T=200,
    dt=0.02,
    meas_noise_std=0.05,
    alpha_noise_est=0.05,
):
    optimizer = optim.Adam(controller.parameters(), lr=1e-3)

    for epoch in range(num_epochs):
        optimizer.zero_grad()

        # Random setpoint between -1 and 1 each epoch
        setpoint = (torch.rand(1).item() - 0.5) * 2.0
        meas_noise_std_i = torch.rand(1).item() * 1.0

        xs, us = simulate_episode(
            controller,
            plant,
            setpoint,
            T=T,
            dt=dt,
            device=device,
            train_mode=True,
            meas_noise_std=meas_noise_std_i,
            alpha_noise_est=alpha_noise_est,
        )

        setpoint_tensor = torch.tensor([setpoint], device=device)
        target_traj = setpoint_tensor.expand_as(xs)

        # Tracking loss on TRUE state
        tracking_loss = ((xs - target_traj) ** 2).mean()

        # Small penalty on control effort
        effort_loss = 1e-3 * (us ** 2).mean()

        loss = tracking_loss + effort_loss
        loss.backward()
        optimizer.step()

        if (epoch + 1) % 50 == 0:
            print(
                f"Epoch {epoch + 1}: loss={loss.item():.4f}, "
                f"setpoint={setpoint:.2f}"
            )


def simulate_episode_eval(
    controller,
    plant,
    setpoint,
    T=200,
    dt=0.02,
    device="cpu",
    train_mode=True,
    meas_noise_std=0.05,
    alpha_noise_est=0.05,
):
    """
    Simulate one trajectory for a fixed setpoint.

    controller     : NeuralPID module
    plant          : FirstOrderPlant instance (process noise inside)
    setpoint       : float
    meas_noise_std : sigma_m in y = x + sigma_m * N(0,1)
    alpha_noise_est: smoothing factor for noise variance estimator

    returns:
        xs: [T, 1] true states over time
        us: [T, 1] control signals over time
    """
    if train_mode:
        controller.train()
    else:
        controller.eval()

    # True state
    x = torch.zeros(1, device=device)         # x0 = 0

    # First measurement (at t=0)
    if meas_noise_std > 0.0:
        meas_noise = meas_noise_std * torch.randn_like(x)
    else:
        meas_noise = 0.0
    y = x + meas_noise

    # PID-like internal states (based on noisy signals)
    i_term = torch.zeros(1, device=device)
    prev_e = torch.zeros(1, device=device)

    # Noise variance estimator
    noise_var_hat = torch.full_like(x, 1e-6)  # shape [1], same as x, e, i, d
    noise_hat = noise_var_hat.sqrt()

    setpoint_tensor = torch.tensor([setpoint], device=device)

    xs = []
    us = []

    # For prediction using deterministic model: we need a,b
    a = plant.a
    b = plant.b

    for t in range(T):
        # Error based on noisy measurement
        e = setpoint_tensor - y
        i_term = i_term + e * dt
        d_term = (e - prev_e) / dt
        prev_e = e

        # Controller sees (e, I, D, noise_hat)
        u = controller(e, i_term, d_term, noise_hat)

        # Plant step: true state evolves with process noise
        mult = 1
        if t > T/2:
          x_next = plant.step(x, u, 1)
          mult = 100
        else:
          x_next = plant.step(x, u)

        # New measurement
        if meas_noise_std > 0.0:
            meas_noise = meas_noise_std * torch.randn_like(x_next)
        else:
            meas_noise = 0.0
        y_next = x_next + meas_noise * mult

        # --- Noise level estimation (based on prediction error) ---
        # Predict next measurement using deterministic model (no noise)
        y_pred = y + dt * (-a * y + b * u)
        residual = y_next - y_pred   # includes process + measurement noise
        noise_var_hat = (
            (1.0 - alpha_noise_est) * noise_var_hat
            + alpha_noise_est * (residual ** 2)
        )
        noise_hat = (noise_var_hat + 1e-8).sqrt()

        # Move to next step
        x = x_next
        y = y_next

        xs.append(x)
        us.append(u)

    xs = torch.stack(xs)  # [T, 1] true states
    us = torch.stack(us)  # [T, 1] controls
    return xs, us

# ---------- Classical PID controller ----------
class ClassicalPID:
    def __init__(self, Kp=2.0, Ki=0.5, Kd=0.1):
        self.Kp = Kp
        self.Ki = Ki
        self.Kd = Kd
        self.integral = None
        self.prev_error = None

    def reset(self):
        self.integral = 0.0
        self.prev_error = 0.0

    def step(self, error, dt):
        if self.integral is None:
            self.integral = 0.0
            self.prev_error = error.item()

        self.integral += error.item() * dt
        derivative = (error.item() - self.prev_error) / dt
        self.prev_error = error.item()

        u = (
            self.Kp * error.item() +
            self.Ki * self.integral +
            self.Kd * derivative
        )
        return torch.tensor([u], dtype=torch.float32, device=error.device)

def simulate_episode_pid(pid, plant, setpoint, T=200, dt=0.02,
                         device="cpu", meas_noise_std=0.05):

    pid.reset()

    x = torch.zeros(1, device=device)
    xs, us = [], []

    # initial measurement
    y = x + meas_noise_std * torch.randn_like(x)

    for t in range(T):
        e = torch.tensor([setpoint], device=device) - y

        u = pid.step(e, dt)

        mult = 1
        if t > T/2:
          x_next = plant.step(x, u, 1)
          mult = 100
        else:
          x_next = plant.step(x, u)

        y = x + meas_noise_std * torch.randn_like(x) * mult

        x = x_next
        xs.append(x)
        us.append(u)

    return torch.stack(xs), torch.stack(us)

# ---------- Neural controller WITHOUT noise input ----------
class NeuralPID_NoNoise(nn.Module):
    def __init__(self, hidden_size=32):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(3, hidden_size),
            nn.Tanh(),
            nn.Linear(hidden_size, 1),
        )

    def forward(self, e, i, d):
        inp = torch.stack([e, i, d], dim=-1)
        u = self.net(inp).squeeze(-1)
        return u

def simulate_episode_no_noise(
    controller,
    plant,
    setpoint,
    T=200,
    dt=0.05,
    device="cpu",
    train_mode=True,
    meas_noise_std=0.05,
    alpha_noise_est=0.05,
):
    """
    Simulate one trajectory for a fixed setpoint.

    controller     : NeuralPID module
    plant          : FirstOrderPlant instance (process noise inside)
    setpoint       : float
    meas_noise_std : sigma_m in y = x + sigma_m * N(0,1)
    alpha_noise_est: smoothing factor for noise variance estimator

    returns:
        xs: [T, 1] true states over time
        us: [T, 1] control signals over time
    """
    if train_mode:
        controller.train()
    else:
        controller.eval()

    # True state
    x = torch.zeros(1, device=device)         # x0 = 0

    # First measurement (at t=0)
    if meas_noise_std > 0.0:
        meas_noise = meas_noise_std * torch.randn_like(x)
    else:
        meas_noise = 0.0
    y = x + meas_noise

    # PID-like internal states (based on noisy signals)
    i_term = torch.zeros(1, device=device)
    prev_e = torch.zeros(1, device=device)

    # Noise variance estimator
    noise_var_hat = torch.full_like(x, 1e-6)  # shape [1], same as x, e, i, d
    noise_hat = noise_var_hat.sqrt()

    setpoint_tensor = torch.tensor([setpoint], device=device)

    xs = []
    us = []

    # For prediction using deterministic model: we need a,b
    a = plant.a
    b = plant.b

    for t in range(T):
        # Error based on noisy measurement
        e = setpoint_tensor - y
        i_term = i_term + e * dt
        d_term = (e - prev_e) / dt
        prev_e = e

        # Controller sees (e, I, D, noise_hat)
        u = controller(e, i_term, d_term)

        # Plant step: true state evolves with process noise
        mult = 1
        if t > T/2:
          x_next = plant.step(x, u, 1)
          mult = 100
        else:
          x_next = plant.step(x, u)
        #x_next = plant.step(x, u)

        # New measurement
        if meas_noise_std > 0.0:
            meas_noise = meas_noise_std * torch.randn_like(x_next)
        else:
            meas_noise = 0.0
        y_next = x_next + meas_noise * mult

        # --- Noise level estimation (based on prediction error) ---
        # Predict next measurement using deterministic model (no noise)
        y_pred = y + dt * (-a * y + b * u)
        residual = y_next - y_pred   # includes process + measurement noise
        noise_var_hat = (
            (1.0 - alpha_noise_est) * noise_var_hat
            + alpha_noise_est * (residual ** 2)
        )
        noise_hat = (noise_var_hat + 1e-8).sqrt()

        # Move to next step
        x = x_next
        y = y_next

        xs.append(x)
        us.append(u)

    xs = torch.stack(xs)  # [T, 1] true states
    us = torch.stack(us)  # [T, 1] controls
    return xs, us

def train_controller_no_noise(
    controller,
    plant,
    device="cpu",
    num_epochs=300,
    T=200,
    dt=0.05
):
    optimizer = optim.Adam(controller.parameters(), lr=1e-3)

    for epoch in range(num_epochs):
        optimizer.zero_grad()

        # Random setpoint between -1 and 1 each epoch
        setpoint = (torch.rand(1).item() - 0.5) * 2.0
        meas_noise_std_i = torch.rand(1).item() * 1.0

        xs, us = simulate_episode_no_noise(
            controller,
            plant,
            setpoint,
            T=T,
            dt=dt,
            device=device,
            train_mode=True,
            meas_noise_std = meas_noise_std_i
        )

        setpoint_tensor = torch.tensor([setpoint], device=device)
        target_traj = setpoint_tensor.expand_as(xs)

        # Tracking loss on TRUE state
        tracking_loss = ((xs - target_traj) ** 2).mean()

        # Small penalty on control effort
        effort_loss = 1e-3 * (us ** 2).mean()

        loss = tracking_loss + effort_loss
        loss.backward()
        optimizer.step()

        if (epoch + 1) % 50 == 0:
            print(
                f"Epoch {epoch + 1}: loss={loss.item():.4f}, "
                f"setpoint={setpoint:.2f}"
            )


# ---------- Main: compare before vs after training ----------

if __name__ == "__main__":
    device = "cpu"  # change to "cuda" if you have a GPU
    dt = 0.05
    T = 600
    setpoint = 1.0

    # Tunable noise levels
    process_noise_std = 0.1   # sigma_p
    meas_noise_std = 0.05     # sigma_m
    alpha_noise_est = 0.05    # 0.01–0.1 is typical

    plant = FirstOrderPlant(a=1.0, b=1.0, dt=dt, noise_std=process_noise_std)
    controller = NeuralPID(hidden_size=32).to(device)

    # Optional: fix seed for reproducible noise
    torch.manual_seed(0)

    # --- 1. Simulate BEFORE training ---
    with torch.no_grad():
        xs_before, us_before = simulate_episode(
            controller,
            plant,
            setpoint,
            T=T,
            dt=dt,
            device=device,
            train_mode=False,
            meas_noise_std=meas_noise_std,
            alpha_noise_est=alpha_noise_est,
        )

    # --- 2. Train controller (it learns to use noise_hat) ---
    print("Training controller with noise estimator...")
    train_controller(
        controller,
        plant,
        device=device,
        num_epochs=300,
        T=T,
        dt=dt,
        meas_noise_std=meas_noise_std,
        alpha_noise_est=alpha_noise_est,
    )

    # --- 3. Simulate AFTER training ---
    with torch.no_grad():
        xs_after, us_after = simulate_episode(
            controller,
            plant,
            setpoint,
            T=T,
            dt=dt,
            device=device,
            train_mode=False,
            meas_noise_std=meas_noise_std,
            alpha_noise_est=alpha_noise_est,
        )

    # --- 4. Plot step responses (true state) ---
    time = torch.arange(T) * dt

    plt.figure()
    plt.plot(time.numpy(), xs_before.cpu().numpy(), label="Before training (true x)")
    plt.plot(time.numpy(), xs_after.cpu().numpy(), label="After training (true x)")
    plt.axhline(setpoint, linestyle="--", label="Setpoint")
    plt.xlabel("Time [s]")
    plt.ylabel("State x (true)")
    plt.title("Adaptive neural PID with noise-level input")
    plt.legend()
    plt.grid(True)
    plt.show()
    
    controller_no_noise = NeuralPID_NoNoise(hidden_size=32).to(device)
    T = 300
    train_controller_no_noise(
            controller_no_noise,
            plant,
            device=device,
            num_epochs=300,
            T=T,
            dt=dt
        )

    # --- Simulate adaptive NN controller ---
    T = 1000
    xs_adapt, _ = simulate_episode_eval(
        controller, plant, setpoint,
        T=T, dt=dt, device=device,
        train_mode=False,
        meas_noise_std=meas_noise_std,
        alpha_noise_est=alpha_noise_est,
    )

    # --- Simulate non-adaptive NN controller ---
    xs_nonoise, _ = simulate_episode_no_noise(
        controller_no_noise, plant, setpoint,
        T=T, dt=dt, device=device,
        train_mode=False,
        meas_noise_std=meas_noise_std,
        alpha_noise_est=alpha_noise_est,
    )

    # --- Simulate classical PID ---
    pid = ClassicalPID(Kp=1.0, Ki=0.5, Kd=0.)
    xs_pid, _ = simulate_episode_pid(
        pid,
        plant,
        setpoint,
        T=T,
        dt=dt,
        device=device,
        meas_noise_std=meas_noise_std,
    )

    # --- Plot ---
    time = torch.arange(T) * dt

    plt.figure(figsize=(10, 5))
    plt.plot(time, xs_adapt.detach().cpu().numpy(), label="Adaptive NN", linewidth=2)
    plt.plot(time, xs_nonoise.detach().cpu().numpy(), label="NN w/o noise input")
    plt.plot(time, xs_pid.detach().cpu().numpy(), label="Classical PID")
    plt.axhline(setpoint, linestyle="--", color="gray", label="Setpoint")
    plt.xlabel("Time [s]")
    plt.ylabel("True state x")
    plt.title("Controller Performance Comparison")
    plt.legend()
    plt.grid(True)
    plt.show()

